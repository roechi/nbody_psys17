\documentclass[a4paper,11pt]{scrartcl} %Standard A4, 11pt Font Größe
\usepackage{fullpage} %weniger Rand
\usepackage[utf8]{inputenc} %richtige Kodierung, auch für Umlaute
% \usepackage{german} %Deutsch mit Zeilenumbrüchen
% \usepackage[german]{babel}
\usepackage{latexsym} %laden von weiteren mathematischen Symbolen
\usepackage{amssymb} % mathematische Symbolzeichensätze (z.B. \mathbb{)
\usepackage{graphicx} %Figures und Subfigures
\usepackage{caption}
\usepackage{subcaption}
\usepackage[obeyspaces,hyphens]{url}
\usepackage{cite}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{amsmath}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage{listings}
\usepackage{xcolor}
\usepackage{textcomp}

\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}

\lstset{
morekeywords={pragma},
    backgroundcolor=\color{lbcolor},
    tabsize=4,
  language=C++,
  captionpos=b,
  tabsize=3,
  frame=lines,
  numbers=left,
  numberstyle=\tiny,
  numbersep=5pt,
  breaklines=true,
  showstringspaces=false,
  basicstyle=\footnotesize,
  directivestyle={\color{red}},
%  identifierstyle=\color{magenta},
  keywordstyle=\color[rgb]{0,0,1},
  commentstyle=\color{olive},
  stringstyle=\color{red}
  }






\definecolor{lightgray}{rgb}{0.6,0.6,0.6}
\definecolor{darkgray}{rgb}{0.3,0.3,0.3}
\newcommand{\err}[1]{$^{\textcolor{red}{#1}}$}
\newcommand{\fl}[1]{\colorbox{lightgray!20}{\path{#1}}}
\newcommand{\cd}[1]{\sethlcolor{darkgray} \textcolor{white}{\hl{\texttt{#1}}}}
\newcommand*{\vv}[1]{\vec{\mkern0mu#1}}

%Header und Titel
\title{N-Body Simulation}
\subtitle{VL Parallele Systeme, HTW Berlin, SS2017}
\author{Richard Remus, Jonas Jaszkowic}
\date{}

%----------------------------------------------------------------------
\begin{document}
\maketitle
% \tableofcontents

\section{Introduction}
Implementing a N-body simulation breaks down to solving the N-body problem of predicting the individual motions of a group of $n$ objects interacting with each other gravitationally. The exact solution to this problem has a time complexity of $\mathcal{O}(n^2)$ which means that it is not possible to solve it efficiently in an appropriate period of time, especially when the number of objects is large. Reducing time complexity can either be done by using approximate methods which produce a "good enough" solution or by parallelizing the algorithm on multi-core processors. For this work, we focus on the latter.

\section{N-body problem}
The N-body problem is a generalized form of the famous two-body and three-body problem which are dealing with the same question: determining the motions of two or three bodies interacting with each other gravitationally. An explicit analytical solution is known to the two-body problem, i.e. simple functions $\vv{r_1}(t)$ and $\vv{r_2}(t)$ that takes only the time $t$ as a parameter and calculates the corresponding position of both bodies given only the initial conditions. However, up to today no analytical solution in the form of $\vv{r_i}(t)$ functions has been found for the three-body problem or the n-body problem. \cite{nbodysolve} The most straight-forward methods are called \textit{direct} methods or \textit{particle-particle} methods. For these problems, a number of numerical solutions are known.
\subsection{Definition}
The n-body problem is given by $n$ point masses $m_i > 0$ and $n$ initial position vectors $\vv{r_i}$ for $i=1,2,...,n$ in a three-dimensional reference system $\mathbb{R}^3$, their mutual gravitational attraction being the single force acting on them. \cite{meyer2008introduction}Given these initial conditions, the task can now be stated as: \textit{Find the position vectors for each body given a time $t$.}
\subsection{Derivation}
Finding the body positions boils down to calculating the acceleration for each body. Using Newton' second law of motion
\begin{align*}
F = m \cdot a 	
\end{align*}\\
we can state that mass times acceleration of the $i$th body is equal to the sum of the forces acting on this particular body. The sum of the forces can be calculated using Newton's universal law of gravity
\begin{align*}
F = \gamma \cdot \frac{m_1m_2}{r^2}	
\end{align*}\\
where $\gamma$ is the gravitational constant, and the superposition principle
\begin{align*}
\vv{F_{res}} = \vv{F_1} + \vv{F_2} + ... + \vv{F_n}	
\end{align*}\\
and the direction of this force defined by
\begin{align*}
\vv{q_j} -\vv{q_i}~/~||\vv{q_j} - \vv{q_i}||
\end{align*}
With these basic laws we can derive the acceleration $a_i$ for every body:
\begin{align*}
	m_i \cdot a_i &= F\\
	m_i \cdot a_i &= \gamma \sum\limits_{j=1}^N \frac{m_i m_j}{||\vv{q_j} - \vv{q_i}||^2}  \\
	\vec{a}^{\,}_i \cdot m_i &= \gamma \sum\limits_{j=1}^N \frac{m_i m_j}{||\vv{q_j} - \vv{q_i}||^2} \cdot \frac{(\vv{q_j} - \vv{q_i})}{||\vv{q_j} - \vv{q_i}||} \\
	\vv{a_i} &= \gamma \sum\limits_{j=1}^N \frac{m_j \cdot (\vv{q_j} - \vv{q_i})}{||\vv{q_j} - \vv{q_i}||^3}
\end{align*}\\
In order to avoid division by zero in the distance calculation $||\vv{q_j} - \vv{q_i}||$ we introduce a softening factor $\epsilon$:

\begin{align*}
	\vv{a_i} &= \gamma \sum\limits_{j=1}^N \frac{m_j \cdot (\vv{q_j} - \vv{q_i})}{(||\vv{q_j} - \vv{q_i}||^2 + \epsilon^2)^\frac{3}{2}}
\end{align*}
With this equation we have deducted the acceleration $\vv{a_i}$ of each body. Using infinitesimal time steps and the laws $v = a\cdot t$ and $s=v\cdot t$, we can iteratively calculate the postion of each body for every time $t$.

\section{Algorithm}
With the above physical equations we can formulate an algorithm for the simulation of the body positions over time given an initial configuration. This algorithm uses the \textit{direct} method and features no further optimizations beside the parallelization that is applied later on. The core algorithm consists of a nested for loop that iterates for each body $i$ over all other bodies $j$ in order to accumulate the forces acting on body $i$. It is important to note that we have to accumulate all forces \textit{before} the calculation of velocity and position can accur, otherwise the update of the position would lead to incorrect results.
\begin{algorithm}[H]
\caption{Update body positions for the given timestep $\Delta$}
\begin{algorithmic}[1]
\Procedure{UpdateStep}{$bodies$,~$\Delta$}
   \For{each body $i$ in $bodies$}
      \State $\vv{a_i} \gets 0$ \Comment{Reset forces for $i$}
      \For{each body $j \neq i$ in $bodies$}
        \State $\vv{a_i} \gets \vv{a_i} + $ CalculateForce($j,i$)
      \EndFor
   \EndFor
   \For{each body $i$}
      \State $\vv{v_i} \gets \vv{v_i} + \Delta * \vv{a_i}$ \Comment{Update velocity}
      \State $\vv{r_i} \gets \vv{r_i} + \Delta * \vv{v_i}$ \Comment{Update position}
   \EndFor
\EndProcedure\\
\Procedure{CalculateForce}{$j,~i$}
	\State \Return $\gamma \frac{m_j \cdot (\vv{q_j} - \vv{q_i})}{(||\vv{q_j} - \vv{q_i}||^2 + \epsilon^2)^\frac{3}{2}}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Because the calculation of the force for each body is independent of previous steps or partial results the nested for-loop can be fully parallelized. The same applies for the second for-loop that updates the positions and velocities.

\section{Implementation}
The simulation and the core algorithm was implemented in \texttt{C/C++} with OpenMP \cite{openmp} and OpenCL \cite{opencl} as parallelization frameworks. For developing and debugging we used the CLion IDE \cite{clion} on two identical MacBook Pro machines running macOS Sierra.

\subsection{Software design}
TODO: description
\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{img/classes.png}
	\caption{Architectural overview of the classes involved in the simulation.}
	\label{fig:classes}
\end{figure}

\subsection{Astronomical Units}
Distances, masses and velocities in the universe lead to large numbers that might not fit in floating
point numbers. Because many OpenCL vendors do not support double precision numbers, we scale these values to astronomical units that will fit in single precision floating points. In astronomical units, time is
measured in years, distances in AU and masses in solar-masses:

\begin{align*}
	1~yr &= 365.25 * 86400~s = 31557600~s \\
	1~AU &= 149597870700~m \\
	1~M &=  1.98892 \cdot 10^{30}~kg
\end{align*}

With these values we can scale the gravitational constant accordingly \cite{astrounits}:

\begin{align*}
	6.674 \cdot 10^{-11} \frac{m^3}{kg \cdot s^2}
	& =  6.674 \cdot 10^{-11} \cdot 2.98692\cdot 10^{-34} \frac{AU^3}{kg \cdot s^2}\\
	& = 6.674 \cdot 10^{-11} \cdot 2.98692\cdot 10^{-34} \cdot 1.98892 \cdot 10^{30} \frac{AU^3}{M \cdot s^2} \\
	& = 6.674 \cdot 10^{-11} \cdot 2.98692\cdot 10^{-34} \cdot 1.98892 \cdot 10^{30} \cdot 9.95844249\cdot 10^{14} \frac{AU^3}{M \cdot yr^2}\\
	& = 39.445 \frac{AU^3}{M \cdot yr^2}
\end{align*}

\section{Parallelization}
\subsection{OpenMP}
OpenMP (\textit{Open Multi-Processing}) is an application programming interface that enables parallelization through the use of multiple threads that are executed concurrently. OpenMP is a high-level API that lightens the user's workload with a set of simple compiler directives, library routines and environment variables that enable nearly-automatic parallelization. It is especially easy to parallelize even nested for-loops as long as some prerequisites are fulfilled. For example a simple two-dimensional for loop can be parallelized with the pragma \texttt{\#pragma omp parallel for collapse(2) \{...\}}. This leads to the creation of \texttt{OMP\_NUM\_THREADS} threads, each executing an equally large part of this loop. The environmental variable \texttt{OMP\_NUM\_THREADS} can be set to an arbitrary value before executing the code. For all practical purposes the number of threads is limited to the number of (virtual) CPUs on the machine. Setting this number to a higher value than available CPUs will \textbf{not} lead to faster execution times but in fact will slow down the execution. Therefore it is advised to set $1 \leq $ \texttt{OMP\_NUM\_THREADS} $\leq $ \texttt{NUM\_CPUs}.\\

\begin{lstlisting}[escapeinside={\X\X}, caption={Part of the code that is parallelized using OpenMP}, label={lst:openmppar}]
void OmpSimulator::addForces() {

X\textcolor{orange}{\#pragma}X omp parallel for
    for (int k = 0; k < this->num_bodies; ++k) {
        this->bodies[k].resetForce();
    }

X\textcolor{orange}{\#pragma}X omp parallel for collapse(2)
    for (int i = 0; i < this->num_bodies; i++) {
        for (int j = 0; j < this->num_bodies; j++) {
            if (i != j) {
                this->bodies[i].addForce(this->bodies[j]);
            }
        }
    }

X\textcolor{orange}{\#pragma}X omp parallel for
    for (int i = 0; i < this->num_bodies; i++) {
        this->bodies[i].update(UPDATE_STEP);
    }

}
\end{lstlisting}

\subsection{OpenCL}
The \textit{Open Computing Language} (OpenCL) is a general-purpose framework for parallelization on heterogeneous platforms. It enables the processing power of CPUs and GPUs. OpenCL specifies it's own programming language \texttt{OpenCL C} that is based on \texttt{C99} and \texttt{C++}. The core concept of OpenCL is the use of so called \textit{kernels}, functions that are executed on an OpenCL device. Following the SPMD (single program, multiple data) approach, this function is applied to each \textit{work item} in parallel. When the number of \textit{compute units} (CUs) is smaller than the number of work items, the workload is equally distributed in work \textit{work groups}. The number of work items in a work group is called \textit{local size}, the total number of work items is called \textit{global size} with the property that the global size is equal to the number of work groups times the according local size. By adjusting these parameters the degree of parallelization can be adjusted, similar to setting \texttt{OMP\_NUM\_THREADS} in the OpenMP framework. The main advantage of OpenCL over OpenMP is the possibility to leverage the compute units available on the GPU. Because the GPU has far more compute units than any CPU, it is perfectly suited to achieve a high degree of parallelization.
\newpage
\begin{lstlisting}[escapeinside={\X\X}, caption={Kernel code for the OpenCL parallelization}, label={lst:openclpar}]

kernel void nbody_move(global float* masses,
                       global float* positions,
                       global float* velocities,
                       global float* forces,
                       int NUM_BODIES,
                       float STEP_SIZE,
                       int WORK_GROUP_SIZE)
{
    const float GRAVITATIONAL_CONSTANT = 39.5f;
    const float EPS = 10;

    // Calculate forces
    for(int n = 0; n < WORK_GROUP_SIZE; n++) {
        int a1d = (get_global_id(0) * WORK_GROUP_SIZE) + n;
        int a2d = a1d * 2;
        float a_rx = positions[a2d];
        float a_ry = positions[a2d+1];
        float fx = 0.0;
        float fy = 0.0;
        for(int i = 0; i < NUM_BODIES; i++) {
            int b1d = i;
            int b2d = i * 2;
            if(b1d != a1d) {
                float b_rx = positions[b2d];
                float b_ry = positions[b2d+1];
                float mass = masses[b1d];
                float dx = b_rx - a_rx;
                float dy = b_ry - a_ry;
                float dist = sqrt(pow(dx,2) + pow(dy,2));
                float F = (mass / pow(dist*dist + EPS*EPS, 1.5));
                fx += F * dx;
                fy += F * dy;
            }
        }
        forces[a2d] = GRAVITATIONAL_CONSTANT * fx;
        forces[a2d+1] = GRAVITATIONAL_CONSTANT * fy;
    }

    // Update positions
    for (int a = 0; a < WORK_GROUP_SIZE; ++a) {
        int a1d = (get_global_id(0) * WORK_GROUP_SIZE) + a;
        int a2d = a1d * 2;
        float fx = forces[a2d];
        float fy = forces[a2d+1];
        velocities[a2d] += STEP_SIZE * fx ;
        velocities[a2d+1] += STEP_SIZE * fy;
        positions[a2d] += STEP_SIZE * velocities[a2d];
        positions[a2d+1] += STEP_SIZE * velocities[a2d+1];
    }

}

\end{lstlisting}

\section{Initital configurations}
TODO: proof of concept with solar system configuration, effect of varying epsilon and gravitational constant, example images

\section{Benchmarks}
TODO: include all benchmarks, test on different machine!, don't forget sequential execution

\section{Discussion}

\bibliography{bibliography}{}
\bibliographystyle{plainurl}
\end{document}
